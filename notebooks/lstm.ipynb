{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07785c01-b3a6-4395-a249-bed2eaa36485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff53001-add9-4d1d-8b05-e908ded20020",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce0469d-efc8-4c4b-9836-7104356a45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_class import ChessGame, ChessMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f90a40f-c7ab-4895-a51f-d8de77f9f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which PGN File To Train\n",
    "max_games = 100000\n",
    "asset_dir = 'asset'\n",
    "file_name = '2023_10000_games.pgn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fced4681-e4d8-4147-9367-35bc57c118f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_item_to_file(games, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(games, file)\n",
    "\n",
    "def load_item_from_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print('loading item from cache...')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            items = pickle.load(file)\n",
    "        print('loaded')\n",
    "        return items\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_pgns(file_path, num_games=None, start_index=0, encoding=\"utf-8\"):\n",
    "    games = []\n",
    "    with open(file_path, \"r\", encoding=encoding) as file:\n",
    "        for _ in tqdm(range(start_index), desc='Skipping games', unit='game', leave=False):\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                break\n",
    "        for _ in tqdm(range(num_games), desc='Loading games', unit='game', leave=True) if num_games else iter(int, 1):\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                break\n",
    "            games.append(game)\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b94b25d-f0dd-43fa-8402-10e8873b97d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading item from cache...\n",
      "loaded\n",
      "loading item from cache...\n",
      "loaded\n",
      "loading item from cache...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "pgns = None\n",
    "assets_path = os.path.join(os.getcwd(), asset_dir)\n",
    "single_path = os.path.join(assets_path, file_name)\n",
    "\n",
    "cached_pgns_file = file_name.split('.')[0] + '_pgn.pkl'\n",
    "cached_urls_file = file_name.split('.')[0] + '_urls_list.pkl'\n",
    "cached_ratings_file = file_name.split('.')[0] + 'ratings_list.pkl'\n",
    "cached_games_file = file_name.split('.')[0] + 'game_arrays.pkl'\n",
    "cached_pgns_path = os.path.join(assets_path, cached_pgns_file)\n",
    "cached_urls_path = os.path.join(assets_path, cached_urls_file)\n",
    "cached_ratings_path = os.path.join(assets_path, cached_ratings_file)\n",
    "cached_games_path = os.path.join(assets_path, cached_games_file)\n",
    "\n",
    "chess_games_loaded = True\n",
    "urls_list = load_item_from_file(cached_urls_path)\n",
    "ratings_list = load_item_from_file(cached_ratings_path)\n",
    "game_arrays = load_item_from_file(cached_games_path)\n",
    "\n",
    "if ratings_list is None:\n",
    "    print('Creating new ratings_list and urls_list...')\n",
    "if game_arrays is None:\n",
    "    print('Creating new game_arrays...')\n",
    "    chess_games_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a25e0af-303e-4dd4-a489-479c03b134a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chess_games_to_arrays(games_generator):\n",
    "    def rating_to_group(rating):\n",
    "        rating = int(rating)\n",
    "        if rating < 800:\n",
    "            return 0\n",
    "        elif rating >= 2400:\n",
    "            return 9\n",
    "        return int(rating)//200 - 3\n",
    "\n",
    "    attributes = [\"ply_count\", \"time_category\", \"classification_name\", \"count_legal_moves\", \"force_moves_percent\",\n",
    "                  \"game_state\", \"distance\", \"is_endgame\", \"has_increment\", \"in_time_trouble\", \"can_dirty_flag\",\n",
    "                  \"is_check\", \"is_double_check\", \"is_discovered_check\", \"is_capture\", \"is_threat\", \"is_developing\",\n",
    "                  \"is_retreating\", \"was_hanging\", \"is_hanging\", \"was_true_hanging\", \"is_true_hanging\", \"is_create_tension\",\n",
    "                  \"is_resolve_tension\", \"is_maintain_tension\", \"start_square\", \"end_square\", \"threats\", \n",
    "                  \"create_tension\", \"maintain_tension\", \"resolve_tension\", \"piece_value\"]\n",
    "    \n",
    "    game_arrays = []\n",
    "    ratings_list = []\n",
    "    urls_list = []\n",
    "    for i, game in enumerate(tqdm(games_generator, total=max_games, desc=\"Processing games\")):\n",
    "        elo_w, elo_b, url = game.white_elo, game.black_elo, game.url\n",
    "        total_plies = game.total_ply\n",
    "        df = pd.DataFrame(columns=attributes)\n",
    "        for j, move in enumerate(game.moves):\n",
    "            move_row = {attribute: getattr(move, attribute, None) for attribute in attributes}\n",
    "            df.loc[j] = move_row\n",
    "        df['ply_count'] = df['ply_count'] / total_plies\n",
    "        df['count_legal_moves'] = df['count_legal_moves'] / 128\n",
    "        df['distance'] = (df['distance'] - 1) / 6\n",
    "\n",
    "        df['prev_end_square'] = df['end_square'].shift(1).fillna(64)\n",
    "        df['prev_threats'] = df['threats'].shift(1).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "        df['prev_create_tension'] = df['create_tension'].shift(1).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "        df['last_move_end_square'] = df['end_square'].shift(2).fillna(64)\n",
    "        df['last_move_create_tension'] = df['create_tension'].shift(2).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "        df['last_move_threats'] = df['threats'].shift(2).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "    \n",
    "        df['is_reacting'] = df.apply(lambda row: row['prev_end_square'] in (row['create_tension'] | row['threats']), axis=1) | \\\n",
    "                            (df['prev_end_square'] == df['end_square']) | \\\n",
    "                            df.apply(lambda row: row['start_square'] in row['prev_threats'], axis=1)\n",
    "        df['is_same_piece'] = df['last_move_end_square'] == df['start_square']\n",
    "        df['veni_vidi_vici'] = df.apply(lambda row: row['end_square'] in (row['last_move_create_tension'] | row['last_move_threats']), axis=1)\n",
    "        df['is_collinear'] = df.apply(lambda row: row['start_square'] in (row['prev_create_tension'] | row['prev_threats']), axis=1) | \\\n",
    "                            df.apply(lambda row: row['prev_end_square'] in row['create_tension'], axis=1)\n",
    "        df.drop(columns=['prev_end_square', 'last_move_end_square', 'prev_threats', 'last_move_create_tension', 'prev_create_tension',\n",
    "                         'last_move_threats', 'threats', 'create_tension', 'maintain_tension', 'resolve_tension'], inplace=True)\n",
    "\n",
    "        df['moved_piece_king'] = df['piece_value'].apply(lambda x: 1 if x == 6 else 0)\n",
    "        df['moved_piece_queen'] = df['piece_value'].apply(lambda x: 1 if x == 5 else 0)\n",
    "        df['moved_piece_rook'] = df['piece_value'].apply(lambda x: 1 if x == 4 else 0)\n",
    "        df['moved_piece_bishop'] = df['piece_value'].apply(lambda x: 1 if x == 3 else 0)\n",
    "        df['moved_piece_knight'] = df['piece_value'].apply(lambda x: 1 if x == 2 else 0)\n",
    "        df['moved_piece_pawn'] = df['piece_value'].apply(lambda x: 1 if x == 1 else 0)\n",
    "        df['time_category_instant'] = df['time_category'].apply(lambda x: 1 if x == 'instant' else 0)\n",
    "        df['time_category_fast'] = df['time_category'].apply(lambda x: 1 if x == 'fast' else 0)\n",
    "        df['time_category_normal'] = df['time_category'].apply(lambda x: 1 if x == 'normal' else 0)\n",
    "        df['time_category_slow'] = df['time_category'].apply(lambda x: 1 if x == 'slow' else 0)\n",
    "        df['classification_name_Great'] = df['classification_name'].apply(lambda x: 1 if x == 'Great' else 0)\n",
    "        df['classification_name_Good'] = df['classification_name'].apply(lambda x: 1 if x == 'Good' else 0)\n",
    "        df['classification_name_Inaccuracy'] = df['classification_name'].apply(lambda x: 1 if x == 'Inaccuracy' else 0)\n",
    "        df['classification_name_Blunder'] = df['classification_name'].apply(lambda x: 1 if x == 'Blunder' else 0)\n",
    "        df['classification_name_Mistake'] = df['classification_name'].apply(lambda x: 1 if x == 'Mistake' else 0)\n",
    "\n",
    "        df = df.drop(['classification_name', 'time_category', 'piece_value', 'start_square', 'end_square'], axis=1)\n",
    "\n",
    "        game_array_rep = df.astype(float).to_numpy()\n",
    "        game_arrays.append(game_array_rep)\n",
    "        ratings_list.append(rating_to_group((elo_w + elo_b)/2))\n",
    "        urls_list.append(url)\n",
    "    return game_arrays, ratings_list, urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005055e2-ede6-4db8-aec0-ac28156fcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not chess_games_loaded:\n",
    "    pgns = load_item_from_file(cached_pgns_path)\n",
    "    if pgns is None:\n",
    "        pgns = load_pgns(single_path, max_games)\n",
    "        save_item_to_file(pgns, cached_pgns_path)\n",
    "    games_generator = (ChessGame(pgn) for pgn in pgns)\n",
    "    game_arrays, ratings_list, urls_list  = chess_games_to_arrays(games_generator)\n",
    "    save_item_to_file(game_arrays, cached_games_path)\n",
    "    save_item_to_file(ratings_list, cached_ratings_path)\n",
    "    save_item_to_file(urls_list, cached_urls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d91bd34-d874-4446-bebe-c115f3efcf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc6 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc7 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_classification = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc_regression = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "\n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.dropout(F.relu(self.fc1(out)))\n",
    "        out = self.dropout(F.relu(self.fc2(out)))\n",
    "        out = self.dropout(F.relu(self.fc3(out)))\n",
    "        out = self.dropout(F.relu(self.fc4(out)))\n",
    "        out = self.dropout(F.relu(self.fc5(out)))\n",
    "        out = self.dropout(F.relu(self.fc6(out)))\n",
    "        out = self.dropout(F.relu(self.fc7(out)))\n",
    "        classification_output = self.fc_classification(out)\n",
    "        regression_output = self.fc_regression(out)\n",
    "        return classification_output, regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94acc50e-bd1e-4c3c-af67-214d1a0fb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(classification_output, regression_output, target, alpha=0.5):\n",
    "    classification_loss = nn.CrossEntropyLoss()(classification_output, target)\n",
    "    regression_target = target.float()\n",
    "    regression_loss = nn.MSELoss()(regression_output.squeeze(), regression_target)\n",
    "    return alpha * classification_loss + (1 - alpha) * regression_loss\n",
    "\n",
    "def train_model(model, train_loader, optimizer, num_epochs, device, alpha=0.5):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (moves, labels) in enumerate(train_loader):  \n",
    "            moves = moves.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            classification_output, regression_output = model(moves)\n",
    "            loss = combined_loss(classification_output, regression_output, labels, alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    return round(loss.item(),4)\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for moves, labels in test_loader:\n",
    "            moves = moves.to(device)\n",
    "            labels = labels.to(device)\n",
    "            classification_output, _ = model(moves)\n",
    "            probabilities = F.softmax(classification_output, dim=1)\n",
    "\n",
    "            _, predicted = torch.max(classification_output.data, 1)\n",
    "            predicted_probs.extend(probabilities.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test moves: {acc} %')\n",
    "    return predicted_probs, predicted_labels, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79dd763-445c-478b-a3a5-fd9be71a7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 42\n",
    "hidden_size = 128\n",
    "num_classes = 10\n",
    "num_epochs = 12\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0\n",
    "sequence_length = 256 #bucketing to be done\n",
    "batch_size = 100\n",
    "alpha = 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b314a2-9ade-4f64-9767-2297b988287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_game(game, max_length=256, vector_size=42):\n",
    "    padding_length = max_length - len(game)\n",
    "    if padding_length < 0:\n",
    "        return game[:max_length]\n",
    "    else:\n",
    "        padding = np.full((padding_length, vector_size), -1)\n",
    "        return np.vstack((game, padding))\n",
    "\n",
    "padded_games = [pad_game(g, sequence_length) for g in game_arrays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0782522-f62c-45f3-a596-9660710ac84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = padded_games[::5]\n",
    "train_list = [df for i in range(1, 5) for df in padded_games[i::5]]\n",
    "test_ratings = ratings_list[::5]\n",
    "train_ratings = [ratings for i in range(1, 5) for ratings in ratings_list[i::5]]\n",
    "test_urls = urls_list[::5]\n",
    "train_urls = [url for i in range(1, 5) for url in urls_list[i::5]]\n",
    "\n",
    "train_data = [torch.FloatTensor(doc) for doc in train_list]\n",
    "test_data = [torch.FloatTensor(doc) for doc in test_list]\n",
    "train_labels = torch.LongTensor(train_ratings)\n",
    "test_labels = torch.LongTensor(test_ratings)\n",
    "\n",
    "train_dataset = TensorDataset(torch.stack(train_data), train_labels)\n",
    "test_dataset = TensorDataset(torch.stack(test_data), test_labels)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "662d866a-577e-44c3-826e-d0e3b71cd6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (lstm): LSTM(42, 128, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc6): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc7): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_classification): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (fc_regression): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = file_name.split('.')[0] + '_pred.pth'\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8425115-3893-492e-884e-dcad3cc083f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Loss: 1.3541\n",
      "Epoch [2/12], Loss: 1.4483\n",
      "Epoch [3/12], Loss: 1.5122\n",
      "Epoch [4/12], Loss: 1.5727\n",
      "Epoch [5/12], Loss: 1.3966\n",
      "Epoch [6/12], Loss: 1.1679\n",
      "Epoch [7/12], Loss: 1.1844\n",
      "Epoch [8/12], Loss: 1.2206\n",
      "Epoch [9/12], Loss: 1.0635\n",
      "Epoch [10/12], Loss: 1.0401\n",
      "Epoch [11/12], Loss: 1.1917\n",
      "Epoch [12/12], Loss: 1.1964\n",
      "Accuracy of the network on the test moves: 31.975 %\n",
      "CPU times: total: 1min 53s\n",
      "Wall time: 4min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(model, train_loader, optimizer, num_epochs, device, alpha)\n",
    "predicted_probs, predicted_labels, actual_labels = test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1c45a1-0606-42b1-8a99-8aa7efc76029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (lstm): LSTM(42, 128, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc6): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc7): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc_classification): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (fc_regression): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.save(model.state_dict(), model_path)\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "#model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "#model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fae926c5-a0d2-4c4a-8f63-b72c2df34bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6395, 14440, 18049, 19378, 19839, 19961, 19987, 19997, 20000, 20000]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "pred_closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f449a81-7f8b-4a65-94f8-2b83d742b75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Count</th>\n",
       "      <td>1682</td>\n",
       "      <td>2123</td>\n",
       "      <td>2058</td>\n",
       "      <td>2066</td>\n",
       "      <td>2031</td>\n",
       "      <td>2045</td>\n",
       "      <td>2172</td>\n",
       "      <td>2112</td>\n",
       "      <td>1969</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Count</th>\n",
       "      <td>1617</td>\n",
       "      <td>2637</td>\n",
       "      <td>1657</td>\n",
       "      <td>2346</td>\n",
       "      <td>1660</td>\n",
       "      <td>2277</td>\n",
       "      <td>2502</td>\n",
       "      <td>1898</td>\n",
       "      <td>1444</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label               0     1     2     3     4     5     6     7     8     9\n",
       "Actual Count     1682  2123  2058  2066  2031  2045  2172  2112  1969  1742\n",
       "Predicted Count  1617  2637  1657  2346  1660  2277  2502  1898  1444  1962"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truths_counter = Counter(actual_labels)\n",
    "preds_counter = Counter(predicted_labels)\n",
    "actual_df = pd.DataFrame(list(truths_counter.items()), columns=['Label', 'Actual Count'])\n",
    "predicted_df = pd.DataFrame(list(preds_counter.items()), columns=['Label', 'Predicted Count'])\n",
    "merged_df = pd.merge(actual_df, predicted_df, on='Label', how='outer').fillna(0)\n",
    "sorted_df = merged_df.set_index('Label').sort_index()\n",
    "sorted_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b98a3aa5-54e5-4d75-8139-89b9bd50cfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Count</th>\n",
       "      <td>1682.000</td>\n",
       "      <td>2123.000</td>\n",
       "      <td>2058.000</td>\n",
       "      <td>2066.000</td>\n",
       "      <td>2031.000</td>\n",
       "      <td>2045.000</td>\n",
       "      <td>2172.000</td>\n",
       "      <td>2112.000</td>\n",
       "      <td>1969.000</td>\n",
       "      <td>1742.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Count</th>\n",
       "      <td>1617.000</td>\n",
       "      <td>2637.000</td>\n",
       "      <td>1657.000</td>\n",
       "      <td>2346.000</td>\n",
       "      <td>1660.000</td>\n",
       "      <td>2277.000</td>\n",
       "      <td>2502.000</td>\n",
       "      <td>1898.000</td>\n",
       "      <td>1444.000</td>\n",
       "      <td>1962.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correct Predictions</th>\n",
       "      <td>884.000</td>\n",
       "      <td>872.000</td>\n",
       "      <td>454.000</td>\n",
       "      <td>575.000</td>\n",
       "      <td>358.000</td>\n",
       "      <td>499.000</td>\n",
       "      <td>658.000</td>\n",
       "      <td>544.000</td>\n",
       "      <td>496.000</td>\n",
       "      <td>1055.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identify Rate</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label                       0         1         2         3         4  \\\n",
       "Actual Count         1682.000  2123.000  2058.000  2066.000  2031.000   \n",
       "Predicted Count      1617.000  2637.000  1657.000  2346.000  1660.000   \n",
       "Correct Predictions   884.000   872.000   454.000   575.000   358.000   \n",
       "Identify Rate           0.526     0.411     0.221     0.278     0.176   \n",
       "\n",
       "Label                       5         6         7         8         9  \n",
       "Actual Count         2045.000  2172.000  2112.000  1969.000  1742.000  \n",
       "Predicted Count      2277.000  2502.000  1898.000  1444.000  1962.000  \n",
       "Correct Predictions   499.000   658.000   544.000   496.000  1055.000  \n",
       "Identify Rate           0.244     0.303     0.258     0.252     0.606  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects_list = []\n",
    "recall_list = []\n",
    "for i in range(10):\n",
    "    indices = [index for index, value in enumerate(actual_labels) if value == i]\n",
    "    totals = [predicted_labels[ind] for ind in indices]\n",
    "    corrects = [value for value in totals if value == i]\n",
    "    rate = len(corrects)/len(totals)\n",
    "    corrects_list.append(len(corrects))\n",
    "    recall_list.append(rate)\n",
    "\n",
    "sorted_df['Correct Predictions'] = corrects_list\n",
    "sorted_df['Identify Rate'] = pd.Series(recall_list).round(3)\n",
    "sorted_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c702bafc-4c17-4fdc-8fd7-3ab89c7885c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14285, 0.68025, 0.0184)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Some Predictions:\")\n",
    "hard_truths = []\n",
    "overconfidents = []\n",
    "awfuls = []\n",
    "for i, (t,g) in enumerate(zip(actual_labels, predicted_labels)):\n",
    "    truth = predicted_probs[i][t]\n",
    "    guess = predicted_probs[i][g]\n",
    "    if truth < 0.05:\n",
    "        hard_truths.append(i)\n",
    "    if guess > 0.3 and t != g:\n",
    "        overconfidents.append(i)\n",
    "    if t-g > 3:\n",
    "        awfuls.append(i)\n",
    "\n",
    "len(hard_truths) / len(actual_labels), len(overconfidents) / len(actual_labels), len(awfuls) / len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11b729c4-bb39-4257-8c33-88ffbeaef4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2: Predicted=3, Actual=0\n",
      "Probability of Guess: 0.36864498257637024\n",
      "Probability of Truth: 0.00467391312122345\n",
      "\n",
      "Sample 7068: Predicted=1, Actual=3\n",
      "Probability of Guess: 0.373016893863678\n",
      "Probability of Truth: 0.13763035833835602\n",
      "\n",
      "Sample 13012: Predicted=3, Actual=5\n",
      "Probability of Guess: 0.36568471789360046\n",
      "Probability of Truth: 0.057433389127254486\n",
      "\n",
      "Sample 2: Predicted=3, Actual=0\n",
      "Probability of Guess: 0.36864498257637024\n",
      "Probability of Truth: 0.00467391312122345\n",
      "\n",
      "Sample 7406: Predicted=7, Actual=4\n",
      "Probability of Guess: 0.379415363073349\n",
      "Probability of Truth: 0.018493378534913063\n",
      "\n",
      "Sample 12998: Predicted=2, Actual=6\n",
      "Probability of Guess: 0.3759855031967163\n",
      "Probability of Truth: 0.003925181459635496\n",
      "\n",
      "Sample 19999: Predicted=6, Actual=9\n",
      "Probability of Guess: 0.39241600036621094\n",
      "Probability of Truth: 0.007643642369657755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_cool_ind(i):\n",
    "    true_lab = actual_labels[i]\n",
    "    guess_lab = predicted_labels[i]\n",
    "    print(f\"Sample {i}: Predicted={guess_lab}, Actual={true_lab}\")\n",
    "    print(f\"Probability of Guess: {predicted_probs[i][guess_lab]}\")\n",
    "    print(f\"Probability of Truth: {predicted_probs[i][true_lab]}\")\n",
    "    print()\n",
    "\n",
    "overs = len(overconfidents)\n",
    "for i in overconfidents[:overs:overs//3]:\n",
    "    print_cool_ind(i)\n",
    "hards = len(hard_truths)\n",
    "for i in hard_truths[:hards:hards//3]:\n",
    "    print_cool_ind(i)\n",
    "\n",
    "#test_urls[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdc3e094-0f1c-49b7-8507-df96bdcc4c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31975, 0.722, 0.90245, 0.9689, 0.99195, 0.99805, 0.99935, 0.99985, 1.0, 1.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x/20000 for x in pred_closeness]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
