{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07785c01-b3a6-4395-a249-bed2eaa36485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff53001-add9-4d1d-8b05-e908ded20020",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f90a40f-c7ab-4895-a51f-d8de77f9f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which PGN File To Train\n",
    "max_games = 500000\n",
    "asset_dir = 'asset'\n",
    "file_name = '2023_tc_50000_games.pgn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fced4681-e4d8-4147-9367-35bc57c118f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_item_from_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print('loading item from cache...')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            items = pickle.load(file)\n",
    "        print('loaded')\n",
    "        return items\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b94b25d-f0dd-43fa-8402-10e8873b97d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading item from cache...\n",
      "loaded\n",
      "loading item from cache...\n",
      "loaded\n",
      "loading item from cache...\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "pgns = None\n",
    "assets_path = os.path.join(os.getcwd(), asset_dir)\n",
    "single_path = os.path.join(assets_path, file_name)\n",
    "\n",
    "cached_pgns_file = file_name.split('.')[0] + '_pgn.pkl'\n",
    "cached_urls_file = file_name.split('.')[0] + '_urls_list.pkl'\n",
    "cached_ratings_file = file_name.split('.')[0] + '_ratings_list.pkl'\n",
    "cached_games_file = file_name.split('.')[0] + '_game_arrays.pkl'\n",
    "cached_pgns_path = os.path.join(assets_path, cached_pgns_file)\n",
    "cached_urls_path = os.path.join(assets_path, cached_urls_file)\n",
    "cached_ratings_path = os.path.join(assets_path, cached_ratings_file)\n",
    "cached_games_path = os.path.join(assets_path, cached_games_file)\n",
    "\n",
    "chess_games_loaded = True\n",
    "urls_list = load_item_from_file(cached_urls_path)\n",
    "ratings_list = load_item_from_file(cached_ratings_path)\n",
    "game_arrays = load_item_from_file(cached_games_path)\n",
    "\n",
    "if ratings_list is None:\n",
    "    print('Creating new ratings_list and urls_list...')\n",
    "if game_arrays is None:\n",
    "    print('Creating new game_arrays...')\n",
    "    chess_games_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d91bd34-d874-4446-bebe-c115f3efcf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc6 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc7 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_classification = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc_regression = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "\n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.dropout(F.relu(self.fc1(out)))\n",
    "        out = self.dropout(F.relu(self.fc2(out)))\n",
    "        out = self.dropout(F.relu(self.fc3(out)))\n",
    "        out = self.dropout(F.relu(self.fc4(out)))\n",
    "        out = self.dropout(F.relu(self.fc5(out)))\n",
    "        out = self.dropout(F.relu(self.fc6(out)))\n",
    "        out = self.dropout(F.relu(self.fc7(out)))\n",
    "        classification_output = self.fc_classification(out)\n",
    "        regression_output = self.fc_regression(out)\n",
    "        return classification_output, regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94acc50e-bd1e-4c3c-af67-214d1a0fb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(classification_output, regression_output, target, alpha=0.5):\n",
    "    classification_loss = nn.CrossEntropyLoss()(classification_output, target)\n",
    "    regression_target = target.float()\n",
    "    regression_loss = nn.MSELoss()(regression_output.squeeze(), regression_target)\n",
    "    return alpha * classification_loss + (1 - alpha) * regression_loss\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, num_epochs, device, alpha=0.5):\n",
    "    torets = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, (moves, labels) in enumerate(train_loader):  \n",
    "            moves = moves.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            classification_output, regression_output = model(moves)\n",
    "            loss = combined_loss(classification_output, regression_output, labels, alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        #print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        predicted_probs, predicted_labels, actual_labels = test_model(model, test_loader, device)\n",
    "        pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "        toret = [x/20000 for x in pred_closeness]\n",
    "        torets.append(toret)\n",
    "    return torets\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for moves, labels in test_loader:\n",
    "            moves = moves.to(device)\n",
    "            labels = labels.to(device)\n",
    "            classification_output, _ = model(moves)\n",
    "            probabilities = F.softmax(classification_output, dim=1)\n",
    "\n",
    "            _, predicted = torch.max(classification_output.data, 1)\n",
    "            predicted_probs.extend(probabilities.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    #print(f'Accuracy of the network on the test moves: {acc} %')\n",
    "    return predicted_probs, predicted_labels, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b314a2-9ade-4f64-9767-2297b988287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_game(game, max_length=256, vector_size=42):\n",
    "    padding_length = max_length - len(game)\n",
    "    if padding_length < 0:\n",
    "        return game[:max_length]\n",
    "    else:\n",
    "        padding = np.full((padding_length, vector_size), -1)\n",
    "        return np.vstack((game, padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e171dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(padded_games, ratings_list, urls_list, batch_size, fold_number=0):\n",
    "    if fold_number < 0 or fold_number > 4:\n",
    "        raise ValueError(\"fold_number must be between 0 and 4\")\n",
    "    test_list = padded_games[fold_number::5]\n",
    "    #print(len(test_list))\n",
    "    train_list = [df for i in range(5) if i != fold_number for df in padded_games[i::5]]\n",
    "    test_ratings = ratings_list[fold_number::5]\n",
    "    train_ratings = [ratings for i in range(5) if i != fold_number for ratings in ratings_list[i::5]]\n",
    "    test_urls = urls_list[fold_number::5]\n",
    "    train_urls = [url for i in range(5) if i != fold_number for url in urls_list[i::5]]\n",
    "\n",
    "    train_data = [torch.FloatTensor(doc) for doc in train_list]\n",
    "    test_data = [torch.FloatTensor(doc) for doc in test_list]\n",
    "    train_labels = torch.LongTensor(train_ratings)\n",
    "    test_labels = torch.LongTensor(test_ratings)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.stack(train_data), train_labels)\n",
    "    test_dataset = TensorDataset(torch.stack(test_data), test_labels)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, train_urls, test_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85c667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_game_counts = [100, 160, 250, 400, 640, 1000, 1600, 2500, 4000, 6400, 10000, 16000, 25000, 40000, 64000, 100000]\n",
    "sample_arrays = []\n",
    "sample_ratings = []\n",
    "sample_urls = []\n",
    "for multiple in [1,10,100]:\n",
    "    for sample_size, threshold in zip([2000, 625, 2000, 2000, 625], [2, 1, 5, 8, 4]):\n",
    "        game_arrays_sample_list = [arr for i, arr in enumerate(game_arrays) if i%sample_size < threshold*multiple]\n",
    "        ratings_sample_list = [rating for i, rating in enumerate(ratings_list) if i%sample_size < threshold*multiple]\n",
    "        urls_sample_list = [url for i, url in enumerate(urls_list) if i%sample_size < threshold*multiple]\n",
    "        sample_arrays.append(game_arrays_sample_list)\n",
    "        sample_ratings.append(ratings_sample_list)\n",
    "        sample_urls.append(urls_sample_list)\n",
    "sample_arrays.append(game_arrays)\n",
    "sample_ratings.append(ratings_list)\n",
    "sample_urls.append(urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7924d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84adf76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25235344b70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 42\n",
    "hidden_size = 128\n",
    "num_classes = 10\n",
    "num_epochs = 21\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.40\n",
    "sequence_length = 128\n",
    "batch_size = 100\n",
    "alpha = 0.8\n",
    "decay = 0.000010\n",
    "\n",
    "torch.manual_seed(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8425115-3893-492e-884e-dcad3cc083f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is trained on 100 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.05, 0.3, 0.55, 0.65, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 160 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.0625, 0.25, 0.375, 0.46875, 0.5625, 0.65625, 0.75, 0.84375, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 250 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.1, 0.32, 0.42, 0.52, 0.58, 0.7, 0.8, 0.92, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 400 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.125, 0.3, 0.4, 0.5, 0.5875, 0.7125, 0.8, 0.9125, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 640 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.09375, 0.3125, 0.4921875, 0.59375, 0.71875, 0.8359375, 0.9140625, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 1000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.115, 0.325, 0.51, 0.605, 0.71, 0.805, 0.925, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 1600 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.1, 0.2875, 0.5375, 0.74375, 0.928125, 0.996875, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 2500 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.112, 0.324, 0.518, 0.716, 0.812, 0.918, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 4000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.10375, 0.32, 0.51875, 0.7125, 0.81375, 0.91625, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 6400 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.11640625, 0.31796875, 0.525, 0.69765625, 0.80859375, 0.9203125, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 10000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.235, 0.605, 0.7945, 0.914, 0.9675, 0.986, 0.997, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 16000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.2440625, 0.604375, 0.8271875, 0.9346875, 0.9834375, 0.9953125, 0.99875, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 25000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.3054, 0.698, 0.875, 0.9556, 0.9864, 0.997, 0.9996, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 40000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.3195, 0.732625, 0.912375, 0.97825, 0.99475, 0.998875, 0.999875, 1.0, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 64000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.31765625, 0.741875, 0.913359375, 0.976015625, 0.993515625, 0.998046875, 0.999609375, 0.999921875, 1.0, 1.0]\n",
      "\n",
      "The model is trained on 100000 games\n",
      "The model has 337,163 trainable parameters\n",
      "[0.31335, 0.7179, 0.9085, 0.9759, 0.99455, 0.9986, 0.99975, 0.99995, 1.0, 1.0]\n",
      "\n",
      "CPU times: total: 3min 53s\n",
      "Wall time: 9min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, game_arrays_list in enumerate(sample_arrays):\n",
    "    print(f'The model is trained on {total_game_counts[i]} games')\n",
    "    sample_rating = sample_ratings[i]\n",
    "    sample_url = sample_urls[i]\n",
    "    padded_games = [pad_game(g, sequence_length, input_size) for g in game_arrays_list]\n",
    "    train_loader, test_loader, train_urls, test_urls = get_loaders(padded_games, sample_rating, sample_url, batch_size)\n",
    "\n",
    "    model_path = file_name.split('.')[0] + '_pred.pth'\n",
    "    model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model has {num_params:,} trainable parameters')\n",
    "    lists = train_model(model, train_loader, test_loader, optimizer, num_epochs, device, alpha)\n",
    "    predicted_probs, predicted_labels, actual_labels = test_model(model, test_loader, device)\n",
    "    pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "    pred_dist = [5*x/total_game_counts[i] for x in pred_closeness]\n",
    "    print(pred_dist)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae926c5-a0d2-4c4a-8f63-b72c2df34bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6267, 14358, 18170, 19518, 19891, 19972, 19995, 19999, 20000, 20000]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "pred_closeness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
