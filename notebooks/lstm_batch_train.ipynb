{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07785c01-b3a6-4395-a249-bed2eaa36485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff53001-add9-4d1d-8b05-e908ded20020",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce0469d-efc8-4c4b-9836-7104356a45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_class import ChessGame, ChessMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f90a40f-c7ab-4895-a51f-d8de77f9f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which PGN File To Train\n",
    "max_games = 500000 #100000\n",
    "asset_dir = 'asset'\n",
    "file_name = '2023_10000_games.pgn'\n",
    "file_name = '2023_tc_50000_games.pgn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fced4681-e4d8-4147-9367-35bc57c118f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_item_to_file(games, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(games, file)\n",
    "\n",
    "def load_item_from_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print('loading item from cache...')\n",
    "        with open(file_path, 'rb') as file:\n",
    "            items = pickle.load(file)\n",
    "        print('loaded')\n",
    "        return items\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_pgns(file_path, num_games=None, start_index=0, encoding=\"utf-8\"):\n",
    "    games = []\n",
    "    with open(file_path, \"r\", encoding=encoding) as file:\n",
    "        for _ in tqdm(range(start_index), desc='Skipping games', unit='game', leave=False):\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                break\n",
    "        for _ in tqdm(range(num_games), desc='Loading games', unit='game', leave=True) if num_games else iter(int, 1):\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                break\n",
    "            games.append(game)\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b94b25d-f0dd-43fa-8402-10e8873b97d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading item from cache...\n",
      "loaded\n",
      "loading item from cache...\n",
      "loaded\n",
      "loading item from cache...\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "pgns = None\n",
    "assets_path = os.path.join(os.getcwd(), asset_dir)\n",
    "single_path = os.path.join(assets_path, file_name)\n",
    "\n",
    "cached_pgns_file = file_name.split('.')[0] + '_pgn.pkl'\n",
    "cached_urls_file = file_name.split('.')[0] + '_urls_list.pkl'\n",
    "cached_ratings_file = file_name.split('.')[0] + '_ratings_list.pkl'\n",
    "cached_games_file = file_name.split('.')[0] + '_game_arrays.pkl'\n",
    "cached_pgns_path = os.path.join(assets_path, cached_pgns_file)\n",
    "cached_urls_path = os.path.join(assets_path, cached_urls_file)\n",
    "cached_ratings_path = os.path.join(assets_path, cached_ratings_file)\n",
    "cached_games_path = os.path.join(assets_path, cached_games_file)\n",
    "\n",
    "chess_games_loaded = True\n",
    "urls_list = load_item_from_file(cached_urls_path)\n",
    "ratings_list = load_item_from_file(cached_ratings_path)\n",
    "game_arrays = load_item_from_file(cached_games_path)\n",
    "\n",
    "if ratings_list is None:\n",
    "    print('Creating new ratings_list and urls_list...')\n",
    "if game_arrays is None:\n",
    "    print('Creating new game_arrays...')\n",
    "    chess_games_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a25e0af-303e-4dd4-a489-479c03b134a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chess_games_to_arrays(games_generator):\n",
    "    def rating_to_group(rating):\n",
    "        rating = int(rating)\n",
    "        if rating < 800:\n",
    "            return 0\n",
    "        elif rating >= 2400:\n",
    "            return 9\n",
    "        return int(rating)//200 - 3\n",
    "\n",
    "    attributes = [\"ply_count\", \"time_category\", \"classification_name\", \"count_legal_moves\", \"force_moves_percent\",\n",
    "                  \"game_state\", \"distance\", \"is_endgame\", \"has_increment\", \"in_time_trouble\", \"can_dirty_flag\",\n",
    "                  \"is_check\", \"is_double_check\", \"is_discovered_check\", \"is_capture\", \"is_threat\", \"is_developing\",\n",
    "                  \"is_retreating\", \"was_hanging\", \"is_hanging\", \"was_true_hanging\", \"is_true_hanging\", \"is_create_tension\",\n",
    "                  \"is_resolve_tension\", \"is_maintain_tension\", \"start_square\", \"end_square\", \"threats\", \n",
    "                  \"create_tension\", \"maintain_tension\", \"resolve_tension\", \"piece_value\"]\n",
    "    \n",
    "    game_arrays = []\n",
    "    ratings_list = []\n",
    "    urls_list = []\n",
    "    for i, game in enumerate(tqdm(games_generator, total=max_games, desc=\"Processing games\")):\n",
    "        elo_w, elo_b, url = game.white_elo, game.black_elo, game.url\n",
    "        total_plies = game.total_ply\n",
    "        df = pd.DataFrame(columns=attributes)\n",
    "        for j, move in enumerate(game.moves):\n",
    "            move_row = {attribute: getattr(move, attribute, None) for attribute in attributes}\n",
    "            df.loc[j] = move_row\n",
    "        df['ply_count'] = df['ply_count'] / total_plies\n",
    "        df['count_legal_moves'] = df['count_legal_moves'] / 128\n",
    "        df['distance'] = (df['distance'] - 1) / 6\n",
    "\n",
    "        df['prev_end_square'] = df['end_square'].shift(1).fillna(64)\n",
    "        df['prev_threats'] = df['threats'].shift(1).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "        df['prev_create_tension'] = df['create_tension'].shift(1).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "        df['last_move_end_square'] = df['end_square'].shift(2).fillna(64)\n",
    "        df['last_move_create_tension'] = df['create_tension'].shift(2).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "        df['last_move_threats'] = df['threats'].shift(2).fillna({}).apply(lambda x: x if isinstance(x, set) else {})\n",
    "    \n",
    "        df['is_reacting'] = df.apply(lambda row: row['prev_end_square'] in (row['create_tension'] | row['threats']), axis=1) | \\\n",
    "                            (df['prev_end_square'] == df['end_square']) | \\\n",
    "                            df.apply(lambda row: row['start_square'] in row['prev_threats'], axis=1)\n",
    "        df['is_same_piece'] = df['last_move_end_square'] == df['start_square']\n",
    "        df['veni_vidi_vici'] = df.apply(lambda row: row['end_square'] in (row['last_move_create_tension'] | row['last_move_threats']), axis=1)\n",
    "        df['is_collinear'] = df.apply(lambda row: row['start_square'] in (row['prev_create_tension'] | row['prev_threats']), axis=1) | \\\n",
    "                            df.apply(lambda row: row['prev_end_square'] in row['create_tension'], axis=1)\n",
    "        df.drop(columns=['prev_end_square', 'last_move_end_square', 'prev_threats', 'last_move_create_tension', 'prev_create_tension',\n",
    "                         'last_move_threats', 'threats', 'create_tension', 'maintain_tension', 'resolve_tension'], inplace=True)\n",
    "\n",
    "        df['moved_piece_king'] = df['piece_value'].apply(lambda x: 1 if x == 6 else 0)\n",
    "        df['moved_piece_queen'] = df['piece_value'].apply(lambda x: 1 if x == 5 else 0)\n",
    "        df['moved_piece_rook'] = df['piece_value'].apply(lambda x: 1 if x == 4 else 0)\n",
    "        df['moved_piece_bishop'] = df['piece_value'].apply(lambda x: 1 if x == 3 else 0)\n",
    "        df['moved_piece_knight'] = df['piece_value'].apply(lambda x: 1 if x == 2 else 0)\n",
    "        df['moved_piece_pawn'] = df['piece_value'].apply(lambda x: 1 if x == 1 else 0)\n",
    "        df['time_category_instant'] = df['time_category'].apply(lambda x: 1 if x == 'instant' else 0)\n",
    "        df['time_category_fast'] = df['time_category'].apply(lambda x: 1 if x == 'fast' else 0)\n",
    "        df['time_category_normal'] = df['time_category'].apply(lambda x: 1 if x == 'normal' else 0)\n",
    "        df['time_category_slow'] = df['time_category'].apply(lambda x: 1 if x == 'slow' else 0)\n",
    "        df['classification_name_Great'] = df['classification_name'].apply(lambda x: 1 if x == 'Great' else 0)\n",
    "        df['classification_name_Good'] = df['classification_name'].apply(lambda x: 1 if x == 'Good' else 0)\n",
    "        df['classification_name_Inaccuracy'] = df['classification_name'].apply(lambda x: 1 if x == 'Inaccuracy' else 0)\n",
    "        df['classification_name_Blunder'] = df['classification_name'].apply(lambda x: 1 if x == 'Blunder' else 0)\n",
    "        df['classification_name_Mistake'] = df['classification_name'].apply(lambda x: 1 if x == 'Mistake' else 0)\n",
    "\n",
    "        df = df.drop(['classification_name', 'time_category', 'piece_value', 'start_square', 'end_square'], axis=1)\n",
    "\n",
    "        game_array_rep = df.astype(float).to_numpy()\n",
    "        game_arrays.append(game_array_rep)\n",
    "        ratings_list.append(rating_to_group((elo_w + elo_b)/2))\n",
    "        #ratings_list.append([elo_w, elo_b])\n",
    "        urls_list.append(url)\n",
    "    return game_arrays, ratings_list, urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005055e2-ede6-4db8-aec0-ac28156fcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not chess_games_loaded:\n",
    "    pgns = load_item_from_file(cached_pgns_path)\n",
    "    if pgns is None:\n",
    "        pgns = load_pgns(single_path, max_games)\n",
    "        save_item_to_file(pgns, cached_pgns_path)\n",
    "    #games_generator = (ChessGame(pgn) for pgn in pgns)\n",
    "    games_generator = (ChessGame(pgn) for i, pgn in enumerate(pgns) if i % 5 == 0)\n",
    "    game_arrays, ratings_list, urls_list  = chess_games_to_arrays(games_generator)\n",
    "    save_item_to_file(game_arrays, cached_games_path)\n",
    "    save_item_to_file(ratings_list, cached_ratings_path)\n",
    "    save_item_to_file(urls_list, cached_urls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d91bd34-d874-4446-bebe-c115f3efcf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc6 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc7 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_classification = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc_regression = nn.Linear(hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "\n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.dropout(F.relu(self.fc1(out)))\n",
    "        out = self.dropout(F.relu(self.fc2(out)))\n",
    "        out = self.dropout(F.relu(self.fc3(out)))\n",
    "        out = self.dropout(F.relu(self.fc4(out)))\n",
    "        out = self.dropout(F.relu(self.fc5(out)))\n",
    "        out = self.dropout(F.relu(self.fc6(out)))\n",
    "        out = self.dropout(F.relu(self.fc7(out)))\n",
    "        classification_output = self.fc_classification(out)\n",
    "        regression_output = self.fc_regression(out)\n",
    "        return classification_output, regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94acc50e-bd1e-4c3c-af67-214d1a0fb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(classification_output, regression_output, target, alpha=0.5):\n",
    "    classification_loss = nn.CrossEntropyLoss()(classification_output, target)\n",
    "    regression_target = target.float()\n",
    "    regression_loss = nn.MSELoss()(regression_output.squeeze(), regression_target)\n",
    "    return alpha * classification_loss + (1 - alpha) * regression_loss\n",
    "\n",
    "def train_model(model, train_loader, X, y, optimizer, num_epochs, device, alpha=0.5):\n",
    "    torets = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, (moves, labels) in enumerate(train_loader):  \n",
    "            moves = moves.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            classification_output, regression_output = model(moves)\n",
    "            loss = combined_loss(classification_output, regression_output, labels, alpha)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        #predicted_probs, predicted_labels, actual_labels = test_model(model, X, y, device)\n",
    "        #pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "        #toret = [x/20000 for x in pred_closeness]\n",
    "        #torets.append(toret)\n",
    "    #return torets\n",
    "\n",
    "def test_model(model, X, y, device):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    actual_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            moves = X[i].to(device).unsqueeze(0)\n",
    "            labels = torch.tensor([y[i]], device=device)\n",
    "            \n",
    "            classification_output, _ = model(moves)\n",
    "            probabilities = F.softmax(classification_output, dim=1)\n",
    "\n",
    "            _, predicted = torch.max(classification_output.data, 1)\n",
    "            predicted_probs.extend(probabilities.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "            n_samples += 1\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test games: {acc} %')\n",
    "    return predicted_probs, predicted_labels, actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b314a2-9ade-4f64-9767-2297b988287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_game(game, max_length=256, vector_size=42):\n",
    "    padding_length = max_length - len(game)\n",
    "    if padding_length < 0:\n",
    "        return game[:max_length]\n",
    "    else:\n",
    "        padding = np.full((padding_length, vector_size), -1)\n",
    "        return np.vstack((game, padding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496310e",
   "metadata": {},
   "source": [
    "PIECE: [0, 1, 2, 4, 5, 9, 10, 11, 12, 14, 15, 27, 28, 29, 30, 31, 32]\n",
    "TIME: [6, 7, 8, 33, 34, 35, 36]\n",
    "ENGINE: [3, 37, 38, 39, 40, 41]\n",
    "DOMAIN: [13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
    "\n",
    "['ply_count', 'count_legal_moves', 'force_moves_percent', 'game_state',\n",
    "       'distance', 'is_endgame', 'has_increment', 'in_time_trouble',\n",
    "       'can_dirty_flag', 'is_check', 'is_double_check', 'is_discovered_check',\n",
    "       'is_capture', 'is_threat', 'is_developing', 'is_retreating',\n",
    "       'was_hanging', 'is_hanging', 'was_true_hanging', 'is_true_hanging',\n",
    "       'is_create_tension', 'is_resolve_tension', 'is_maintain_tension',\n",
    "       'is_reacting', 'is_same_piece', 'veni_vidi_vici', 'is_collinear',\n",
    "       'moved_piece_king', 'moved_piece_queen', 'moved_piece_rook',\n",
    "       'moved_piece_bishop', 'moved_piece_knight', 'moved_piece_pawn',\n",
    "       'time_category_instant', 'time_category_fast', 'time_category_normal',\n",
    "       'time_category_slow', 'classification_name_Great',\n",
    "       'classification_name_Good', 'classification_name_Inaccuracy',\n",
    "       'classification_name_Blunder', 'classification_name_Mistake']\n",
    "\n",
    "\n",
    "#### PIECE\n",
    "\n",
    "'moved_piece_king'\n",
    "'moved_piece_queen'\n",
    "'moved_piece_rook'\n",
    "'moved_piece_bishop'\n",
    "'moved_piece_knight'\n",
    "'moved_piece_pawn'\n",
    "'distance'\n",
    "'is_check'\n",
    "'is_double_check'\n",
    "'is_discovered_check'\n",
    "'is_capture'\n",
    "'is_developing'\n",
    "'is_retreating'\n",
    "'ply_count'\n",
    "'is_endgame'\n",
    "'count_legal_moves'\n",
    "'force_moves_percent'\n",
    "\n",
    "#### TIME\n",
    "\n",
    "'time_category_instant'\n",
    "'time_category_fast'\n",
    "'time_category_normal'\n",
    "'time_category_slow'\n",
    "'has_increment'\n",
    "'in_time_trouble'\n",
    "'can_dirty_flag'\n",
    "    \n",
    "#### ENGINE\n",
    "\n",
    "'classification_name_Great'\n",
    "'classification_name_Good'\n",
    "'classification_name_Inaccuracy'\n",
    "'classification_name_Blunder'\n",
    "'classification_name_Mistake'\n",
    "'game_state'\n",
    "\n",
    "#### DOMAIN\n",
    "\n",
    "'was_hanging'\n",
    "'is_hanging'\n",
    "'was_true_hanging'\n",
    "'is_true_hanging'\n",
    "'is_create_tension'\n",
    "'is_resolve_tension'\n",
    "'is_maintain_tension'\n",
    "'is_threat'\n",
    "'is_reacting'\n",
    "'is_same_piece'\n",
    "'veni_vidi_vici'\n",
    "'is_collinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e171dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(game_arrays, sequence_length, ratings_list, urls_list, batch_size, fold_number=0):\n",
    "    if fold_number < 0 or fold_number > 4:\n",
    "        raise ValueError(\"fold_number must be between 0 and 4\")\n",
    "    padded_games = [pad_game(g, sequence_length) for g in game_arrays]\n",
    "    test_list = game_arrays[fold_number::5]\n",
    "    train_list = [df for i in range(5) if i != fold_number for df in padded_games[i::5]]\n",
    "    test_ratings = ratings_list[fold_number::5]\n",
    "    \n",
    "    train_ratings = [ratings for i in range(5) if i != fold_number for ratings in ratings_list[i::5]]\n",
    "    test_urls = urls_list[fold_number::5]\n",
    "    train_urls = [url for i in range(5) if i != fold_number for url in urls_list[i::5]]\n",
    "\n",
    "    train_data = [torch.FloatTensor(doc) for doc in train_list]\n",
    "    test_data = [torch.FloatTensor(doc) for doc in test_list]\n",
    "    train_labels = torch.LongTensor(train_ratings)\n",
    "    test_labels = torch.LongTensor(test_ratings)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.stack(train_data), train_labels)\n",
    "    #test_dataset = TensorDataset(torch.stack(test_data), test_labels)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    #test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_data, test_labels, train_urls, test_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0859258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 337,163 trainable parameters\n",
      "Epoch [1/24], Loss: 2.3398\n",
      "Epoch [2/24], Loss: 2.2252\n",
      "Epoch [3/24], Loss: 1.9841\n",
      "Epoch [4/24], Loss: 1.6911\n",
      "Epoch [5/24], Loss: 1.7871\n",
      "Epoch [6/24], Loss: 2.1742\n",
      "Epoch [7/24], Loss: 1.6484\n",
      "Epoch [8/24], Loss: 1.5614\n",
      "Epoch [9/24], Loss: 1.6973\n",
      "Epoch [10/24], Loss: 1.8559\n",
      "Epoch [11/24], Loss: 1.7798\n",
      "Epoch [12/24], Loss: 1.6000\n",
      "Epoch [13/24], Loss: 1.8229\n",
      "Epoch [14/24], Loss: 1.6942\n",
      "Epoch [15/24], Loss: 1.6880\n",
      "Epoch [16/24], Loss: 1.4638\n",
      "Epoch [17/24], Loss: 1.6284\n",
      "Epoch [18/24], Loss: 1.4891\n",
      "Epoch [19/24], Loss: 1.4881\n",
      "Epoch [20/24], Loss: 1.3526\n",
      "Epoch [21/24], Loss: 1.3412\n",
      "Epoch [22/24], Loss: 1.3091\n",
      "Epoch [23/24], Loss: 1.3027\n",
      "Epoch [24/24], Loss: 1.3260\n",
      "Accuracy of the network on the test games: 23.925 %\n",
      "Truncated Game Length: 80\n",
      "Epoch [24/45], Prediction Loss Distribution: [0.23925, 0.5714, 0.7726, 0.8851, 0.94415, 0.97625, 0.98995, 0.99735, 0.99945, 1.0]\n",
      "\n",
      "Continuing Training...\n",
      "Epoch [1/6], Loss: 3.2407\n",
      "Epoch [2/6], Loss: 2.2970\n",
      "Epoch [3/6], Loss: 2.0267\n",
      "Epoch [4/6], Loss: 2.0519\n",
      "Epoch [5/6], Loss: 1.9162\n",
      "Epoch [6/6], Loss: 2.0529\n",
      "Accuracy of the network on the test games: 17.19 %\n",
      "Truncated Game Length: 120\n",
      "Epoch [30/45], Prediction Loss Distribution: [0.1719, 0.45685, 0.67675, 0.8262, 0.9368, 0.986, 0.99665, 0.9999, 1.0, 1.0]\n",
      "\n",
      "Continuing Training...\n",
      "Epoch [1/6], Loss: 2.2676\n",
      "Epoch [2/6], Loss: 1.7587\n",
      "Epoch [3/6], Loss: 2.0242\n",
      "Epoch [4/6], Loss: 2.1266\n",
      "Epoch [5/6], Loss: 1.8791\n",
      "Epoch [6/6], Loss: 1.8891\n",
      "Accuracy of the network on the test games: 16.155 %\n",
      "Truncated Game Length: 60\n",
      "Epoch [36/45], Prediction Loss Distribution: [0.16155, 0.42135, 0.61585, 0.76055, 0.856, 0.9198, 0.9617, 0.9859, 0.9982, 1.0]\n",
      "\n",
      "Continuing Training...\n",
      "Epoch [1/3], Loss: 3.2307\n",
      "Epoch [2/3], Loss: 3.6358\n",
      "Epoch [3/3], Loss: 2.2271\n",
      "Accuracy of the network on the test games: 10.54 %\n",
      "Truncated Game Length: 160\n",
      "Epoch [39/45], Prediction Loss Distribution: [0.1054, 0.25905, 0.40705, 0.52735, 0.63755, 0.7444, 0.84905, 0.93495, 0.9777, 1.0]\n",
      "\n",
      "Continuing Training...\n",
      "Epoch [1/3], Loss: 2.3886\n",
      "Epoch [2/3], Loss: 1.9054\n",
      "Epoch [3/3], Loss: 2.0198\n",
      "Accuracy of the network on the test games: 12.935 %\n",
      "Truncated Game Length: 40\n",
      "Epoch [42/45], Prediction Loss Distribution: [0.12935, 0.31755, 0.47615, 0.607, 0.70665, 0.80265, 0.88125, 0.9377, 0.9806, 1.0]\n",
      "\n",
      "Continuing Training...\n",
      "Epoch [1/3], Loss: 3.4864\n",
      "Epoch [2/3], Loss: 3.4370\n",
      "Epoch [3/3], Loss: 3.2647\n",
      "Accuracy of the network on the test games: 10.58 %\n",
      "Truncated Game Length: 200\n",
      "Epoch [45/45], Prediction Loss Distribution: [0.1058, 0.31495, 0.5228, 0.7303, 0.91875, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(64)\n",
    "input_size = 42\n",
    "hidden_size = 128\n",
    "num_classes = 10\n",
    "num_epochs_l = [24,6,6,3,3,3]\n",
    "num_layers = 2\n",
    "learning_rate_base = 0.0000625\n",
    "dropout_rate = 0.4\n",
    "batch_size = 100\n",
    "alpha = 0.8\n",
    "decay = 0.00001\t\n",
    "sequence_lengths = [80, 120, 60, 160, 40, 200]\n",
    "\n",
    "model_path = file_name.split('.')[0] + '_pred.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "first = True\n",
    "epochs_count = 0\n",
    "totes = sum(num_epochs_l)\n",
    "\n",
    "for seq_i, sequence_length in enumerate(sequence_lengths):\n",
    "    num_epochs = num_epochs_l[seq_i]\n",
    "    learning_rate = learning_rate_base * num_epochs\n",
    "    epochs_count += num_epochs\n",
    "\n",
    "    train_loader, X, y, train_urls, test_urls = get_loaders(game_arrays, sequence_length, ratings_list, urls_list, batch_size)\n",
    "    model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)\n",
    "    if first:\n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'The model has {num_params:,} trainable parameters')\n",
    "        first = False\n",
    "    else:\n",
    "        print('Continuing Training...')\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    lists = train_model(model, train_loader, X, y, optimizer, num_epochs, device, alpha)\n",
    "    predicted_probs, predicted_labels, actual_labels = test_model(model, X, y, device)\n",
    "    pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "    print(\"Truncated Game Length: {}\".format(sequence_length))\n",
    "    print(f'Epoch [{epochs_count}/{totes}], Prediction Loss Distribution: {[x/20000 for x in pred_closeness]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae926c5-a0d2-4c4a-8f63-b72c2df34bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2116, 6299, 10456, 14606, 18375, 20000, 20000, 20000, 20000, 20000]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_closeness = [sum(abs(p - a) <= k for p, a in zip(predicted_labels, actual_labels)) for k in range(10)]\n",
    "pred_closeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f449a81-7f8b-4a65-94f8-2b83d742b75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Count</th>\n",
       "      <td>1625.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label                 0       1       2       3       4        5       6  \\\n",
       "Actual Count     1625.0  2149.0  2091.0  2043.0  2026.0   2116.0  2157.0   \n",
       "Predicted Count     0.0     0.0     0.0     0.0     0.0  20000.0     0.0   \n",
       "\n",
       "Label                 7       8       9  \n",
       "Actual Count     2114.0  2059.0  1620.0  \n",
       "Predicted Count     0.0     0.0     0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truths_counter = Counter(actual_labels)\n",
    "preds_counter = Counter(predicted_labels)\n",
    "actual_df = pd.DataFrame(list(truths_counter.items()), columns=['Label', 'Actual Count'])\n",
    "predicted_df = pd.DataFrame(list(preds_counter.items()), columns=['Label', 'Predicted Count'])\n",
    "merged_df = pd.merge(actual_df, predicted_df, on='Label', how='outer').fillna(0)\n",
    "sorted_df = merged_df.set_index('Label').sort_index()\n",
    "sorted_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b98a3aa5-54e5-4d75-8139-89b9bd50cfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Count</th>\n",
       "      <td>1625.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>2091.0</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correct Predictions</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identify Rate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label                     0       1       2       3       4        5       6  \\\n",
       "Actual Count         1625.0  2149.0  2091.0  2043.0  2026.0   2116.0  2157.0   \n",
       "Predicted Count         0.0     0.0     0.0     0.0     0.0  20000.0     0.0   \n",
       "Correct Predictions     0.0     0.0     0.0     0.0     0.0   2116.0     0.0   \n",
       "Identify Rate           0.0     0.0     0.0     0.0     0.0      1.0     0.0   \n",
       "\n",
       "Label                     7       8       9  \n",
       "Actual Count         2114.0  2059.0  1620.0  \n",
       "Predicted Count         0.0     0.0     0.0  \n",
       "Correct Predictions     0.0     0.0     0.0  \n",
       "Identify Rate           0.0     0.0     0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects_list = []\n",
    "recall_list = []\n",
    "for i in range(10):\n",
    "    indices = [index for index, value in enumerate(actual_labels) if value == i]\n",
    "    totals = [predicted_labels[ind] for ind in indices]\n",
    "    corrects = [value for value in totals if value == i]\n",
    "    rate = len(corrects)/len(totals)\n",
    "    corrects_list.append(len(corrects))\n",
    "    recall_list.append(rate)\n",
    "\n",
    "sorted_df['Correct Predictions'] = corrects_list\n",
    "sorted_df['Identify Rate'] = pd.Series(recall_list).round(3)\n",
    "sorted_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c702bafc-4c17-4fdc-8fd7-3ab89c7885c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.081)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Some Predictions:\")\n",
    "hard_truths = []\n",
    "overconfidents = []\n",
    "awfuls = []\n",
    "for i, (t,g) in enumerate(zip(actual_labels, predicted_labels)):\n",
    "    truth = predicted_probs[i][t]\n",
    "    guess = predicted_probs[i][g]\n",
    "    if truth < 0.05:\n",
    "        hard_truths.append(i)\n",
    "    if guess > 0.3 and t != g:\n",
    "        overconfidents.append(i)\n",
    "    if t-g > 3:\n",
    "        awfuls.append(i)\n",
    "\n",
    "len(hard_truths) / len(actual_labels), len(overconfidents) / len(actual_labels), len(awfuls) / len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11b729c4-bb39-4257-8c33-88ffbeaef4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "slice step cannot be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      9\u001b[0m overs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(overconfidents)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43moverconfidents\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43movers\u001b[49m\u001b[43m:\u001b[49m\u001b[43movers\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m     11\u001b[0m     print_cool_ind(i)\n\u001b[0;32m     12\u001b[0m hards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(hard_truths)\n",
      "\u001b[1;31mValueError\u001b[0m: slice step cannot be zero"
     ]
    }
   ],
   "source": [
    "def print_cool_ind(i):\n",
    "    true_lab = actual_labels[i]\n",
    "    guess_lab = predicted_labels[i]\n",
    "    print(f\"Sample {i}: Predicted={guess_lab}, Actual={true_lab}\")\n",
    "    print(f\"Probability of Guess: {predicted_probs[i][guess_lab]}\")\n",
    "    print(f\"Probability of Truth: {predicted_probs[i][true_lab]}\")\n",
    "    print()\n",
    "\n",
    "overs = len(overconfidents)\n",
    "for i in overconfidents[:overs:overs//3]:\n",
    "    print_cool_ind(i)\n",
    "hards = len(hard_truths)\n",
    "for i in hard_truths[:hards:hards//3]:\n",
    "    print_cool_ind(i)\n",
    "\n",
    "#test_urls[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc3e094-0f1c-49b7-8507-df96bdcc4c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1058, 0.31495, 0.5228, 0.7303, 0.91875, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x/20000 for x in pred_closeness]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
