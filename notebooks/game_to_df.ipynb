{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c258d33f-b27f-4a5c-b3e4-e54472124782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6293c2c9-4a56-4c64-8fe3-12fd9e83d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ece692-19c5-4b39-9de8-e49eb896776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pgns(file_path, num_games=None, start_index=0, encoding=\"utf-8\"):\n",
    "    games = []\n",
    "    with open(file_path, \"r\", encoding=encoding) as file:\n",
    "        for _ in tqdm(range(start_index), desc='Skipping games', unit='game', leave=False):\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                break\n",
    "        for _ in tqdm(range(num_games), desc='Loading games', unit='game', leave=True) if num_games else iter(int, 1):\n",
    "            game = chess.pgn.read_game(file)\n",
    "            if game is None:\n",
    "                break\n",
    "            games.append(game)\n",
    "    return games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53c95ff-73b8-4e58-b278-86d526a6957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading games: 100%|██████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 346.86game/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 309 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "assets_path = os.path.join(os.getcwd(), 'asset')\n",
    "single_path = os.path.join(assets_path, 'rating_split_7_rand/group_9.pgn')\n",
    "games = load_pgns(single_path, 100)\n",
    "game = games[0]\n",
    "board = game.board()\n",
    "\n",
    "#244780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0624c00d-f9f8-4bdd-b626-83e1dcff242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_from_result(result):\n",
    "    if result == '1-0':\n",
    "        return 64\n",
    "    elif result == '0-1':\n",
    "        return -64\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def extract_eval_clk_from_pgn(input, result=''):\n",
    "    clk_pattern = r\"\\[%clk\\s+([0-9:]+)\\]\"\n",
    "    eval_pattern = r\"\\[%eval\\s+([0-9.-]+)\\]\"\n",
    "    mate_pattern = r\"\\[%eval\\s+#([0-9.-]+)\\]\"\n",
    "    clk = re.search(clk_pattern, input)\n",
    "    clk = clk.group(1) if clk else None\n",
    "    eval = re.search(eval_pattern, input)\n",
    "    eval = eval.group(1) if eval else None\n",
    "    if not eval:\n",
    "        eval = re.search(mate_pattern, input)\n",
    "        eval = int(eval.group(1)) if eval else get_eval_from_result(result)\n",
    "        if eval > 0:\n",
    "            eval = 64\n",
    "        else:\n",
    "            eval = -64\n",
    "    return eval, clk\n",
    "\n",
    "def time_control_to_list(time_control_obj):\n",
    "    time_control = [float(x) for x in time_control_obj.split('+')]\n",
    "    time_control += [0] * (2 - len(time_control))\n",
    "    if time_control[0] < 30:\n",
    "        time_control[0] = time_control[0] * 60\n",
    "    return time_control\n",
    "        \n",
    "def eval_to_cp(eval):\n",
    "    eval = float(eval)\n",
    "    return eval * 100\n",
    "\n",
    "def clk_to_time(clk):\n",
    "    h, m, s = clk.split(\":\")\n",
    "    t = int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    return t\n",
    "\n",
    "def eval_to_game_state(value, cuts = None):\n",
    "    if cuts == None:\n",
    "        cuts = [np.inf, 375, 250, 150, 75, 25, -25, -75, -150, -250, -375, -np.inf]\n",
    "    for i in range(len(cuts) - 1):\n",
    "        if cuts[i] >= value > cuts[i + 1]:\n",
    "            return round(1-i/10, 2)\n",
    "\n",
    "def fen_to_array(fen):\n",
    "    piece_mapping = {'p': -1, 'n': -2, 'b': -3, 'r': -4, 'q': -5, 'k': -6,\n",
    "                     'P': 1, 'N': 2, 'B': 3, 'R': 4, 'Q': 5, 'K': 6}\n",
    "    board_fen, turn, castling, en_passant, halfmove, fullmove = fen.split()\n",
    "    board_array = [0] * 64\n",
    "    rank = 7\n",
    "    file = 0\n",
    "    for char in board_fen:\n",
    "        if char.isdigit():\n",
    "            file += int(char)\n",
    "        elif char == '/':\n",
    "            rank -= 1\n",
    "            file = 0\n",
    "        else:\n",
    "            index = rank * 8 + file\n",
    "            board_array[index] = piece_mapping[char]\n",
    "            file += 1\n",
    "    return np.array(board_array)\n",
    "\n",
    "def determine_move_quality(df):\n",
    "    subjective_state = 20 * (df['game_state'] - 0.5) * np.power(-1, np.arange(len(df))) / 10\n",
    "    delta_state = -10 * pd.concat([pd.Series([0.6]), df['game_state']]).diff().iloc[1:] * np.power(-1, np.arange(len(df))) / 10\n",
    "    near_equality = np.abs(subjective_state) < 0.5\n",
    "    decisive_advantage = np.abs(subjective_state) > 0.7\n",
    "    fate_sealed = np.abs(subjective_state) > 0.9\n",
    "\n",
    "    move_quality = np.full(len(df), 4) # Default to 4 (Mistake)\n",
    "    move_quality[(delta_state > .45) | ((delta_state > .35) & decisive_advantage) | ((delta_state > .25) & fate_sealed)] = 5 # Blunder\n",
    "    move_quality[((delta_state < .25) & ~decisive_advantage) | ((delta_state < .35) & near_equality)] = 3 # Inaccuracy\n",
    "    move_quality[(delta_state < .15)] = 2 # Good\n",
    "    move_quality[(delta_state < .05) & (subjective_state > -1)] = 1 # Great\n",
    "    return move_quality.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b06f72-1019-4fa6-b282-c3c4be76f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_to_df(game):\n",
    "    result = game.headers['Result']\n",
    "    board = game.board()\n",
    "    moves = [move for move in game.mainline_moves()]\n",
    "    board = game.board()\n",
    "    node = game\n",
    "    ply = 0\n",
    "    df = pd.DataFrame(columns=['lan', 'game_state', 'time_remain', 'time_spent', 'fen_array', 'fen_string'])\n",
    "    time_controls = time_control_to_list(game.headers['TimeControl'])\n",
    "    current_clock = [time_controls[0] + time_controls[1]]*2\n",
    "    for move in moves:\n",
    "        turn = ply%2\n",
    "        current_clock[turn] += time_controls[1]\n",
    "        ply += 1\n",
    "        node = node.next()\n",
    "        eval, clk = extract_eval_clk_from_pgn(node.comment, result)\n",
    "        eval = eval_to_game_state(eval_to_cp(eval))\n",
    "    \n",
    "        clk = clk_to_time(clk)    \n",
    "        t_spent = current_clock[turn] - clk\n",
    "        current_clock[turn] = clk\n",
    "        \n",
    "        lan = board.lan(move)\n",
    "        fen_str = board.fen()\n",
    "        fen_arr = fen_to_array(fen_str)\n",
    "        board.push(move)\n",
    "        new_row = {'lan': lan, 'game_state': eval, 'time_remain': clk, 'time_spent':t_spent, 'fen_array': fen_arr, 'fen_string': fen_str}\n",
    "        df.loc[ply] = new_row\n",
    "    return df\n",
    "    #df['move_quality'] = determine_move_quality(df)\n",
    "    #df[df['move_quality']>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba54065a-8699-435c-b285-9a2ae7ab2538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.94 s\n",
      "Wall time: 8.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lans = [game_to_df(game)['lan'].tolist() for game in games]\n",
    "len(lans)\n",
    "#df.iloc[1::2]\n",
    "#df['lan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c81c019-6791-416b-9f71-31b3f04b9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torchtext\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acb71a52-9aa7-4d40-810d-1df6474a8971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2819982-0249-474b-934b-027221bc398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lans[:int(len(lans) * 0.7)]\n",
    "validate = lans[int(len(lans) * 0.7):int(len(lans) * 0.85)]\n",
    "test = lans[int(len(lans) * 0.85):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3370222-f41e-482f-8e9c-8ebe24a61107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "['<unk>', '<eos>', 'O-O', 'Ng8-f6', 'Ng1-f3', 'd2-d4', 'Nb1-c3', 'e2-e4', 'd7-d5', 'e7-e6']\n"
     ]
    }
   ],
   "source": [
    "vocab = torchtext.vocab.build_vocab_from_iterator(train, min_freq=10) \n",
    "vocab.insert_token('<unk>', 0)\n",
    "vocab.insert_token('<eos>', 1)\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "print(len(vocab))   \n",
    "print(vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee6878e-6f5b-45fb-af8f-93bb393d9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(games, vocab, batch_size):\n",
    "    data = []                             \n",
    "    for game in games:\n",
    "        if game:\n",
    "            moves = game + ['<eos>']\n",
    "            moves = [vocab[move] for move in game] \n",
    "            data.extend(moves)                                    \n",
    "    data = torch.LongTensor(data)                                 \n",
    "    num_batches = data.shape[0] // batch_size \n",
    "    data = data[:num_batches * batch_size]                       \n",
    "    data = data.view(batch_size, num_batches)                                         \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48f7ae2-6f6c-4ff1-979e-2e9abe66cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = get_data(train, vocab, batch_size)\n",
    "valid_data = get_data(validate, vocab, batch_size)\n",
    "test_data = get_data(test, vocab, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57eee16a-b378-4954-9ed2-3e324979c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, \n",
    "                tie_weights):\n",
    "                \n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, \n",
    "                    dropout=dropout_rate, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        if tie_weights:\n",
    "            assert embedding_dim == hidden_dim, 'cannot tie, check dims'\n",
    "            self.embedding.weight = self.fc.weight\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, src, hidden):\n",
    "        embedding = self.dropout(self.embedding(src))\n",
    "        output, hidden = self.lstm(embedding, hidden)          \n",
    "        output = self.dropout(output) \n",
    "        prediction = self.fc(output)\n",
    "        return prediction, hidden\n",
    "        \n",
    "    def init_weights(self):\n",
    "        init_range_emb = 0.1\n",
    "        init_range_other = 1/math.sqrt(self.hidden_dim)\n",
    "        self.embedding.weight.data.uniform_(-init_range_emb, init_range_emb)\n",
    "        self.fc.weight.data.uniform_(-init_range_other, init_range_other)\n",
    "        self.fc.bias.data.zero_()\n",
    "        for i in range(self.num_layers):\n",
    "            self.lstm.all_weights[i][0] = torch.FloatTensor(self.embedding_dim,\n",
    "                    self.hidden_dim).uniform_(-init_range_other, init_range_other) \n",
    "            self.lstm.all_weights[i][1] = torch.FloatTensor(self.hidden_dim, \n",
    "                    self.hidden_dim).uniform_(-init_range_other, init_range_other) \n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return hidden, cell\n",
    "\n",
    "    def detach_hidden(self, hidden):\n",
    "        hidden, cell = hidden\n",
    "        hidden = hidden.detach()\n",
    "        cell = cell.detach()\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af86ae1-f63e-4798-905b-87925fed38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 1024             # 400 in the paper\n",
    "hidden_dim = 1024                # 1150 in the paper\n",
    "num_layers = 4                   # 3 in the paper\n",
    "dropout_rate = 0.05\n",
    "tie_weights = True                  \n",
    "lr = 1e-3                        # They used 30 and a different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afab7a46-ff6b-4286-a3ca-fbbd32f1c142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 33,684,575 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, tie_weights).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'The model has {num_params:,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6514692-0d36-4457-b614-ba050da9f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, seq_len, num_batches, idx):\n",
    "    src = data[:, idx:idx+seq_len]                   \n",
    "    target = data[:, idx+1:idx+seq_len+1]             \n",
    "    return src, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c21554-ab05-4f32-a758-c3ac73c31a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion, batch_size, seq_len, clip, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    # drop all batches that are not a multiple of seq_len\n",
    "    num_batches = data.shape[-1]\n",
    "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
    "    num_batches = data.shape[-1]\n",
    "\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "    \n",
    "    for idx in tqdm(range(0, num_batches - 1, seq_len), desc='Training: ',leave=False):  # The last batch can't be a src\n",
    "        optimizer.zero_grad()\n",
    "        hidden = model.detach_hidden(hidden)\n",
    "\n",
    "        src, target = get_batch(data, seq_len, num_batches, idx)\n",
    "        src, target = src.to(device), target.to(device)\n",
    "        batch_size = src.shape[0]\n",
    "        prediction, hidden = model(src, hidden)               \n",
    "\n",
    "        prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
    "        target = target.reshape(-1)\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * seq_len\n",
    "    return epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd6122ab-c535-4c41-baa8-4b761010877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion, batch_size, seq_len, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    num_batches = data.shape[-1]\n",
    "    data = data[:, :num_batches - (num_batches -1) % seq_len]\n",
    "    num_batches = data.shape[-1]\n",
    "\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, num_batches - 1, seq_len):\n",
    "            hidden = model.detach_hidden(hidden)\n",
    "            src, target = get_batch(data, seq_len, num_batches, idx)\n",
    "            src, target = src.to(device), target.to(device)\n",
    "            batch_size= src.shape[0]\n",
    "\n",
    "            prediction, hidden = model(src, hidden)\n",
    "            prediction = prediction.reshape(batch_size * seq_len, -1)\n",
    "            target = target.reshape(-1)\n",
    "\n",
    "            loss = criterion(prediction, target)\n",
    "            epoch_loss += loss.item() * seq_len\n",
    "    return epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb49285-2fd1-4816-9602-e5b1d78b5edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 1.000\n",
      "\tValid Perplexity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 1.000\n",
      "\tValid Perplexity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 1.000\n",
      "\tValid Perplexity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 1.000\n",
      "\tValid Perplexity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Perplexity: 1.000\n",
      "\tValid Perplexity: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "seq_len = 50\n",
    "clip = 0.25\n",
    "saved = False\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
    "\n",
    "if saved:\n",
    "    model.load_state_dict(torch.load('best-val-lstm_lm.pt',  map_location=device))\n",
    "    test_loss = evaluate(model, test_data, criterion, batch_size, seq_len, device)\n",
    "    print(f'Test Perplexity: {math.exp(test_loss):.3f}')\n",
    "else:\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train(model, train_data, optimizer, criterion, \n",
    "                    batch_size, seq_len, clip, device)\n",
    "        valid_loss = evaluate(model, valid_data, criterion, batch_size, \n",
    "                    seq_len, device)\n",
    "        \n",
    "        lr_scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best-val-lstm_lm.pt')\n",
    "\n",
    "        print(f'\\tTrain Perplexity: {math.exp(train_loss):.3f}')\n",
    "        print(f'\\tValid Perplexity: {math.exp(valid_loss):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ee4b4ad-021e-497a-9730-64f5a258411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, max_seq_len, temperature, model, vocab, device, real_move, seed=None):\n",
    "    board = chess.Board()\n",
    "    for move in prompt:\n",
    "        board.push(board.parse_san(move))\n",
    "    legal_moves = [board.lan(move) for move in board.legal_moves]\n",
    "    legal_moves_index = [vocab[move] for move in legal_moves]\n",
    "    legal_moves_index = torch.LongTensor(legal_moves_index)\n",
    "\n",
    "    real_ind = vocab[board.lan(board.parse_san(real_move))]\n",
    "    \n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    model.eval()\n",
    "    indices = [vocab[t] for t in prompt]\n",
    "    batch_size = 1\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(max_seq_len):\n",
    "            src = torch.LongTensor([indices]).to(device)\n",
    "            prediction, hidden = model(src, hidden)\n",
    "            \n",
    "            probs = torch.softmax(prediction[:, -1] / temperature, dim=-1)\n",
    "            if legal_moves_index is not None:\n",
    "                mask = torch.zeros_like(probs)\n",
    "                mask[:, legal_moves_index] = 1\n",
    "                probs = probs * mask\n",
    "                probs_sum = probs.sum(dim=-1, keepdim=True)\n",
    "                probs = probs / probs_sum\n",
    "            \n",
    "            #prediction_r = torch.multinomial(probs, num_samples=1).item()\n",
    "            prediction = torch.max(probs, dim=-1)[1].item()         \n",
    "\n",
    "            while prediction == vocab['<unk>']:\n",
    "                prediction = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "            if prediction == vocab['<eos>']:\n",
    "                break\n",
    "            print(probs[0, [real_ind, prediction]], real_ind == prediction)\n",
    "            indices.append(prediction)\n",
    "\n",
    "    itos = vocab.get_itos()\n",
    "    tokens = [itos[i] for i in indices]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6df867e-fc96-4ad1-b63d-affb20438d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0562, 0.0563], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Ng8-f6\n",
      "\n",
      "tensor([0.0475, 0.0490], device='cuda:0') False\n",
      "prediction: Nb1-c3\n",
      "reality: c2-c4\n",
      "\n",
      "tensor([0.0605, 0.0607], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: e7-e6\n",
      "\n",
      "tensor([0.0545, 0.0545], device='cuda:0') True\n",
      "prediction: Nb1-c3\n",
      "reality: Nb1-c3\n",
      "\n",
      "tensor([0.0522, 0.0546], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: d7-d5\n",
      "\n",
      "tensor([0.0554, 0.0564], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: c4xd5\n",
      "\n",
      "tensor([0.0506, 0.0518], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: e6xd5\n",
      "\n",
      "tensor([0.0590, 0.0598], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Bc1-g5\n",
      "\n",
      "tensor([0.0539, 0.0545], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: c7-c6\n",
      "\n",
      "tensor([0.0659, 0.0676], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: e2-e3\n",
      "\n",
      "tensor([0.0557, 0.0575], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Bf8-e7\n",
      "\n",
      "tensor([0.0617, 0.0636], device='cuda:0') False\n",
      "prediction: Bf1-e2\n",
      "reality: Bf1-d3\n",
      "\n",
      "tensor([0.0650, 0.0650], device='cuda:0') True\n",
      "prediction: O-O\n",
      "reality: O-O\n",
      "\n",
      "tensor([0.0708, 0.0726], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Ng1-e2\n",
      "\n",
      "tensor([0.0583, 0.0610], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: h7-h6\n",
      "\n",
      "tensor([0.0759, 0.0798], device='cuda:0') False\n",
      "prediction: O-O\n",
      "reality: Bg5xf6\n",
      "\n",
      "tensor([0.0707, 0.0740], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Be7xf6\n",
      "\n",
      "tensor([0.0798, 0.0798], device='cuda:0') True\n",
      "prediction: O-O\n",
      "reality: O-O\n",
      "\n",
      "tensor([0.0658, 0.0689], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Nb8-d7\n",
      "\n",
      "tensor([0.0707, 0.0724], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Qd1-c2\n",
      "\n",
      "tensor([0.0824, 0.0859], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Rf8-e8\n",
      "\n",
      "tensor([0.0707, 0.0724], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Nc3-d1\n",
      "\n",
      "tensor([0.0820, 0.0858], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Bf6-g5\n",
      "\n",
      "tensor([0.0719, 0.0724], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: f2-f4\n",
      "\n",
      "tensor([0.0702, 0.0736], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Bg5-e7\n",
      "\n",
      "tensor([0.0762, 0.0781], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Nd1-f2\n",
      "\n",
      "tensor([0.0758, 0.0794], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Nd7-f6\n",
      "\n",
      "tensor([0.0762, 0.0781], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: e3-e4\n",
      "\n",
      "tensor([0.0681, 0.0688], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: d5xe4\n",
      "\n",
      "tensor([0.0762, 0.0781], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Nf2xe4\n",
      "\n",
      "tensor([0.0684, 0.0691], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Bc8-g4\n",
      "\n",
      "tensor([0.0825, 0.0845], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Ne4xf6+\n",
      "\n",
      "tensor([0.4980, 0.5020], device='cuda:0') False\n",
      "prediction: Kg8-h8\n",
      "reality: Be7xf6\n",
      "\n",
      "tensor([0.0825, 0.0845], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Ne2-g3\n",
      "\n",
      "tensor([0.0819, 0.0858], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Qd8xd4+\n",
      "\n",
      "tensor([0.5039, 0.5039], device='cuda:0') True\n",
      "prediction: Kg1-h1\n",
      "reality: Kg1-h1\n",
      "\n",
      "tensor([0.1096, 0.1148], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Ra8-d8\n",
      "\n",
      "tensor([0.0989, 0.1016], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: h2-h3\n",
      "\n",
      "tensor([0.1413, 0.1480], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Qd4xd3\n",
      "\n",
      "tensor([0.1102, 0.1130], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Qc2xd3\n",
      "\n",
      "tensor([0.1413, 0.1480], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Rd8xd3\n",
      "\n",
      "tensor([0.1102, 0.1130], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Kh1-h2\n",
      "\n",
      "tensor([0.1238, 0.1296], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Bf6-h4\n",
      "\n",
      "tensor([0.1239, 0.1270], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Ng3-h1\n",
      "\n",
      "tensor([0.0988, 0.1035], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Bg4-f5\n",
      "\n",
      "tensor([0.1105, 0.1129], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Ra1-c1\n",
      "\n",
      "tensor([0.1098, 0.1150], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Re8-e2\n",
      "\n",
      "tensor([0.1649, 0.1690], device='cuda:0') False\n",
      "prediction: a2-a3\n",
      "reality: Kh2-g1\n",
      "\n",
      "tensor([0.1098, 0.1150], device='cuda:0') False\n",
      "prediction: g7-g6\n",
      "reality: Rd3-d2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 1\n",
    "seed = 0\n",
    "temperature = 0.5\n",
    "\n",
    "game = load_pgns(os.path.join(assets_path, 'qgdm.pgn'))[0]\n",
    "lans_ = game_to_df(game).lan.tolist()\n",
    "\n",
    "for i, move in enumerate(lans_):\n",
    "    if i < 1:\n",
    "        continue\n",
    "    moves = lans_[:i]\n",
    "    generation = generate(moves, max_seq_len, temperature, model, vocab, device, move, seed)\n",
    "    print('prediction:', generation[-1])\n",
    "    print('reality:', move)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
